{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4757b8e9-fbb5-4f8d-ab76-e7a8a12c227e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de12af125a14737a1def199def26f31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce51efbd0894481af5e7c1f3892083c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56775da8dea044028c7b21c67868aae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f5a25a64ff048ce987c6fbcf68a4a42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/307M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from zonos.model import Zonos\n",
    "from zonos.conditioning import make_cond_dict\n",
    "\n",
    "# model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-hybrid\", device=\"cuda\")\n",
    "model = Zonos.from_pretrained(\"Zyphra/Zonos-v0.1-transformer\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b389ec91-a4bf-4007-9d10-35b36263281d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85be3c4ef9a649a38dd00e372e61246e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ResNet293_SimAM_ASP_base.pt:   0%|          | 0.00/397M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5dfd7c01374a90a0bfc7deb12799b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ResNet293_SimAM_ASP_base_LDA-128.pt:   0%|          | 0.00/265k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wav, sampling_rate = torchaudio.load(\"lina.mp3\")\n",
    "speaker = model.make_speaker_embedding(wav, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d468984b-4a59-495d-b8fe-94fd9b947966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0828eaa53e754aafaa5ae9f8ac788b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Audio(value=b'ID3\\x04\\x00\\x00\\x00\\x00\\x00#TSSE\\x00\\x00\\x00\\x0f\\x00\\x00\\x03Lavf58.76.100\\x00\\x00\\x00\\x00\\x00\\x0…"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import Audio\n",
    "with open('lina.mp3','rb') as stream:\n",
    "    data = stream.read()\n",
    "\n",
    "Audio(value=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f2188f4-f348-417a-ad8e-d1d04fb70265",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_dict = make_cond_dict(text=\"AI can do pretty wonderful things after all, this model is simply amazing!\", speaker=speaker, language=\"en-us\")\n",
    "conditioning = model.prepare_conditioning(cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "168f5bfe-4b14-46ba-82ec-86fd672049a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  16%|█▋        | 421/2588 [00:03<00:19, 109.76it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd745782eb64d239da92008945f8d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Audio(value=b'RIFFH\\xe8\\x0c\\x00WAVEfmt \\x10\\x00\\x00\\x00\\x03\\x00\\x01\\x00D\\xac\\x00\\x00\\x10\\xb1\\x02\\x00\\x04\\x00 \\…"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes = model.generate(conditioning)\n",
    "\n",
    "wavs = model.autoencoder.decode(codes).cpu()\n",
    "torchaudio.save(\"sample.wav\", wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "with open('sample.wav', 'rb') as stream:\n",
    "    data = stream.read()\n",
    "\n",
    "\n",
    "Audio(value=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c59f14d-674f-4051-8697-b3601e35879e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_dict = make_cond_dict(text='Der chinesische Automarkt ist von den Dimensionen her gigantisch und gerät mehr und mehr unter chinesische Kontrolle.', speaker=speaker, language=\"de\")\n",
    "conditioning = model.prepare_conditioning(cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3fce579-3aed-46c7-921e-920bd63e18f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:   1%|          | 24/2588 [00:00<00:31, 81.92it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m codes \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconditioning\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m wavs \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39mdecode(codes)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      4\u001b[0m torchaudio\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msample_de.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, wavs[\u001b[38;5;241m0\u001b[39m], model\u001b[38;5;241m.\u001b[39mautoencoder\u001b[38;5;241m.\u001b[39msampling_rate)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Zonos/zonos/model.py:240\u001b[0m, in \u001b[0;36mZonos.generate\u001b[0;34m(self, prefix_conditioning, audio_prefix_codes, max_new_tokens, cfg_scale, batch_size, sampling_params, progress_bar, callback)\u001b[0m\n\u001b[1;32m    237\u001b[0m next_token \u001b[38;5;241m=\u001b[39m sample_from_logits(logits, generated_tokens\u001b[38;5;241m=\u001b[39mdelayed_codes[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, :offset], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msampling_params)\n\u001b[1;32m    238\u001b[0m eos_in_cb0 \u001b[38;5;241m=\u001b[39m next_token[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meos_token_id\n\u001b[0;32m--> 240\u001b[0m remaining_steps[eos_in_cb0[:, \u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mminimum(remaining_steps[eos_in_cb0[:, \u001b[38;5;241m0\u001b[39m]], \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m9\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    241\u001b[0m stopping \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m eos_in_cb0[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    243\u001b[0m eos_codebook_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9\u001b[39m \u001b[38;5;241m-\u001b[39m remaining_steps\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "codes = model.generate(conditioning)\n",
    "\n",
    "wavs = model.autoencoder.decode(codes).cpu()\n",
    "torchaudio.save(\"sample_de.wav\", wavs[0], model.autoencoder.sampling_rate)\n",
    "\n",
    "with open('sample_de.wav', 'rb') as stream:\n",
    "    data = stream.read()\n",
    "\n",
    "Audio(value=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1638ef5f-a2f9-4858-ae15-1eaa9edbb420",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.listdir('/home/app/.cache/huggingface/hub')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24612980-e766-41c0-a66e-5cf531fb78a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find /home/ -type f -iname \"model.safetensors\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
