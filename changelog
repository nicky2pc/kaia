4.0.5
    Foundation
        Added a blueprint for file-cache that can be used in resources and file-caches
    Avatar
        The services depending on external files are refactored and brought to the resource folder instead of folder settings
    Chara
        Improved decision on which templates to expand in paraphrasing
    Grammatron
        Test clarifying the behaviour of the tameplate with None value
    Kaia
        Adjusting to switch to the resource folders in Avatar
        Music handling is extracted to the interface. Skills adjusted.
    

4.0.4
    Kaia can now detect faces on images and run personalized notifications
    Avatar:
        TimerEvent -> TickEvent
        UserWalkIn service
        VectorIdentificator now works for SpeakerIdentification
        Small fixes and improvements
    Brainbox:
        - InsightFace is imlemented
        - Representation is refactored in flow, MinimalRepresentation is added
        - Small improvements in deployment
    Chara:
        - code to set up the face identification (notebook is missing)
        - Paraphrases are improved. Notebook for paraphrases is added
    Foundation Kaia:
        - Yearly repetitions
    Grammatron:
        - Template now has a default name set to its content
    Phonix:
        - Sox output is supported (works better at Raspberry pie)
    Kaia:
        - Tinkering in Assistant
        -  WalkIn skill, not-yet-official WorkoutSkill
        - WebCam support in JS

4.0.3
    Avatar:
        Better error processing in server
        You can now exclude certain types from `get` and `tail`
    Bugfixing:
        Kaia skills, Kaia driver, Phonix
    Kaia:
        WebCam Images processing available in the frontend.
4.0.2
    Fixes so it works on my kitchen
    Avatar
        Sound unblocking service
        Graph building
        Avatar deamon can now report processing events to a separate client
        Async client & tail requests
        Type constaints on client
        All messaging requests are now POST
    Grammatron
        Draft for documentation
    Kaia
        Small changes
        Avatar debug container and tests
    Phonix
        Optimization: async client and type filtration so it works on slow systems
        Running via pypi package



4.0.1
    Avatar:
        - Images are passed by file_id, not by base64, to decrease the size of db
        - Typing is improved; The tool to draw a graph of the assembled system is added
        - Binding of rules is improved: you can easily setup service to ignore the outputs of particular publisher, or to accept only them
    Chara:
        - Paraphrase is operational again
    Eaglesong:
        - Listens are simplified, they just carry the payload now
    Foundation:
        - Loc now reads the environment.env file in / on startup
    Grammatron:
        - Grammatron now contains a skeleton to parse Template to TemplateDubs to Sequences
    Kaia
        - app is now better configurable
        - cleanup in assistant, not-used features are removed
        - the skills are fixed, all of them are now with the proper unit tests
    Phonix
        - many small experiment-driven improvements
        - monitoring component now shows file list as well
        - volume is now also processed by phonix (tested at Linux only)
    General:
        - project's requirements are updated


4.0.0
    - EVERYTHING has changed
    - Grammatron is now hosting templates
      - templates are much better, much more logical
      - templates better support flective languages (e.g. Russian).
      - fuzzy-search algorithm is implemented, Kleene-star cunstructions can be parsed on the Whisper- or VOSK outputs
    - Avatar is now a center of the whole system
      - The middleware that converts code to a character, encapsulating voice, image, personality
      - Defines messaging bus, and all interaction between frontend and backend is done through the bus
      - Avatar server hosts the bus, as well as auxiliary functionality for the web-based frontend
      - Avatar daemon processes some of the messages, turning text to sounds and sounds to text
    - Phonix daemon now does audio control on Python
      - the use case is a smart speaker without screen, e.g. on Raspberry Pie
      - Phonix utilizes pyaudio and porcupine to emit the events in the Avatar bus
      - Phonix also plays the audio command from the bus
    - Kaia is now exactly what the name suggests - Kitchen Assistant
      - The driver that adopts Avatar's bus to the eaglesong flow
      - The way skills are orchestrated to work together
      - Several self-contained (i.e. not requiring internet connection) skills
      - A simple frontend that DOES NOT support microphone yet. The development of the web-based frontend with a supported audio is ongoing in https://github.com/toplenboren/0-latency-voice-uploader/

3.7.2.
    - audio_control is fixed, now diagnostics methods work as they should
    - buttons fully work (but are a bit ugly). Cookbook skill now demonstrates buttons as well
3.7.1.
    - chara.drama is added, allows to write scenarios for a free conversation
3.7.0.
    MAJOR REFACTORING
    - foundation_kaia: Now contains Marhalling, Fork, Addresses/Prompts and other things that are used everywhere
    - brainbox: updated to accomodate foundation_kaia
    - eaglesong:
        - Now also contain Templates (previously known as dubs)
        - Templates are significantly improved, the structure streamlined, the algorithms improved, the connotations simplified
        - Is prepared for a release as a separate project
    - chara:
        - Now contains paraphrasing project that allows you to set the paraphrases for your characters
    - avatar:
        - Now is a separate subproject
        - Now contains a free-speech analysis with the new Templates
    - kaia:
        - skills and talents are refactored to match the new architecture, otherwise unchanged
        - buttons are prototyped but they don't yet work
    - project requirements updated and streamlined
3.6.3.
    - BrainBox:
        - All deciders are build from exact python version (3.x.x)
        - PiperTraining is finalized
        - Small improvements
        - Flow module to build flows with BrainBox tasks
    - Eaglesong:
        - small improvement in test scenarios
    - Avatar:
        - VOSK can now be used for speech-to-text
        - Content management is refactored
    - Demo:
        - experimental frontend support is added
    - Kaia:
        - Skill's interaction is improved; Cookbook skill is added
    - New project: Chara
        - Will contain AI-intensive recipies for Kaia functionality
        - Started with a voice clone recipe
3.6.1
    - BrainBox:
        - Vosk, Zonos, minot changes in Piper, PiperTraining
3.6.0
    - BrainBox:
        - Many small improvements in existing skills
        - KohyaSS and PiperTraining to train Lora for images and piper model for voice. Underconstruction.
        - OpenVoice, VideoToImages and Resemble-Enhance are finalized
    - Avatar:
        - The model now has "activity". The activity changes by request of the client
    - Kaia:
        - updated to reflect avatar's changes

3.5.4
    - BrainBox:
        - Windows compatibility
        - Small bugfixes
        - Cancel buttons now work
        - OpenVoice, Piper works (suboptimally), Resemble-Enhance is still in progress

3.5.3
    - Brainbox: WD14, Espeak deciders, piper, openvoice prototypes
    - Small bug fixes in Brainbox + 1 big: BrainBox can now run inside container itself
3.5.2
    - Fixed bug with BrainBox not working on the machine without GPU
    - Fixed bud with downloadable models which didn't work
    - Self-test now contains the source code of the test
    - Fixed bug with some deciders unable to download models

3.5.1
    - BrainBox polished: containerized version now works with local user, unsuccessful installation raises
    - Restarts of kaia client and servers are correctly processed
    - AvatarAPI put to kaia context to simplify access
3.5.0
    - Big update
    - brainbox and eaglesong are separated into stand-alone folders and will at some point become standalone projects
    - kaia is switched to the new communication architecture completely, tests are improved, the coverage increased
    - old projects, `zoo`, `kaia.bro` and `kaia.ml` are removed to focus on things that are the essence of the project. Some will be restored.
3.4.1
    - New architecture, compatible with sound processing in the browser, is introduced
3.4.0
    - ComfyUI, Ollama, KohyaSS, WD14Tagger are completed; Rhasspy, Oobabooga and Automatic1111 are moved to Legacy
    - Free templates with PredefinedBindings are simplified; more logic is moved to objects instead of bindings.
    - To generate Prompts, Ontologies can now be used that define grids of parameters and allow bulding prompts on top of that
3.3.1.
    - Test server for the new protocol is now dockerized
3.3.0.
    - ComfiUI decider is added to Brainbox, with TextToImage, Upscale and WD14Tagger workflows
    - WD14Tagger is added to Brainbox
    - Upscale endpoint is added to Automatic1111
    - Small refactoring in Brainbox
    - LoRA training recipe components
3.2.0.
    - Avatar Service is significantly refactored:
        - There is no narrator anymore. Avatar holds the State. If there is a need of story, the state must be modified by the external service
        - Avatar keeps track of its procedures
        - NLU is now completely on the Avatar side. Avatar thus incapsulates all BrainBox calls in the app
    - RhasspyKaldi NLU is recognized: now we can have several Kaldi models, e.g. one model per complex skill
    - Input preprocessing is modified: Listen can now store various additional attributes, and PartialListenTranslators modify the stack's behaviour accordingly


3.1.0.
    - A draft for new bus-based backend and frontend
3.0.0.
    - Brainbox is refactored to self-testing docker-based containers. `Deployment` is now part of Brainbox
    - Dubs are moved to repo's root. Templates syntaxis is greatly improved, metadata for paraphrasees are added
    - Eaglesong uses IAssert in Scenarios for better assertion
    - Avatar supports paraphrases, image handling is refactored to MediaLibraryManager
    - Narration library is added, with the aim to content creation. Paraphrases are supported
    - AudioControl is greatly streamlined, all the processing logic is moved downstream
    - Skills are now supporting paraphrases
    - Kaia's demo is moved from `my` to `demos/kaia`. `my` folder is now empty

2.1.1.
    - Dubs parsing is improved
    - Executors require command in array format for linux-compatibility
    - Chat is Kaia GUI is now scrollable, not selectable
    - Traffic between browser and Kaia GUI is optimized
2.1.0.
    - New deciders in Brainbox, also new architecture of the deciders, based on Docker
    - Brainbox's performance is optimized for the case with lots of tasks
    - Rhasspy is now used only as NLU unit. Voice input is done by kaia.kaia.audio_control
    - ML recepy on voice cloning is ready
    - Demo that runs on the PC under Windows and Linux is available
    - "Good image" added to ChangeImage skill.
    - Initialization of assistant is redesigned as a wrap around KaiaAssistant, eliminating some rare-occuring problems
    - Initialization of KaiaCoreService is streamlined
2.0.0
    - First fully working version
    - persona -> avatar, simplified
    - brainbox is roughly finalized, few new deciders
    - kaia is introduced, contains everything required for voice assistant
    - no changes in bro, eaglesong
1.0.0
    - eaglesong refactored with better input management (`input = yield Listen()` instead of yield Listen(); input = context.input`)
    - BrainBox, a web-server-decorator for different models, is introduced
    - Automatic1111 tryouts are now the part of BrainBox
    - persona module is introduced, currently contains everything required for voiceovers
0.4.2
    - Full-fledged testing for telegram skills
    - Group control bot is refactored to Eaglesong, unit tests added
0.4.1
    - More skills for group control, also those are prettified and can now be used as examples
0.4.0
    - Chatbot to control telegram with 2 skills: autorestriction and whois
    - kaia.app is simplified, storage and messenger is no longer a part of config and must be provided to services separately
0.3.0
    - bro module for smart home controlling
0.2.0
    - fix error in infra tests
    - demos on images: how to create character
0.1.0
    - layer of chatflow logic abstracted from telegram
    - chat driver for IPython notebooks
    - lots of cleanup
    - narrator protorype
    - complete set of examples with documentation
0.0.3
    - TelegramBridge refactoring: the main loop that handles automata moved to Interpreters
0.0.2
   - tests moved to kaia_tests
   - upgraded SqlMessenger, message can have many tags
   - kaia.infra.tasks with a bridge to huge async tasks
0.0.1
  - tests for Storage don't trigger warnings
  - Subroutine.return_value -> returned_value(), better handling of returning one value
  - Menu skill demo
0.0.0
  - Very first version
